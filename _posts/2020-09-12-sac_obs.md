---
title:  "Curious Observation in SAC Implementation"
permalink: /posts/2020/09/12/sac_obs
tags:
  - reinforcement-learning
  - pytorch
categories: 
  - implementation
---

While working on my entry for the [MineRL 2020](https://www.aicrowd.com/challenges/neurips-2020-minerl-competition#f.a.q) competition, I had to implement the soft-actor critic (SAC) algorithm from scratch. However, while coding the calculation of the log probabilities of the actions, I came across a tiny obstacle.

For context, this involves calculating $ \log\pi (\mathbf{a}\|\mathbf{s}) $ You see, I took this part of the code from the [stable-baselines implementation](), 